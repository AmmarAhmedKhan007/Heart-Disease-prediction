# Heart-Disease-prediction
## `Goal of the Analysis`
1. `Data Preparation:`

    `Cleaning and Preprocessing:` 
    Ensure the dataset is free of inconsistencies, missing values, and outliers to improve model accuracy.

    `Feature Engineering:`
    Transform or create features to enhance model performance.

    `Data Splitting:` 
    Divide the dataset into training and testing sets for model validation.

2. `Exploratory Data Analysis (EDA):`
    Gain insights into the data, understanding relationships and distributions that might influence model selection and performance.

3. `Model Training:`
    Selection of Models: Choose a diverse set of models to compare. This might include decision trees, random forest and XGboost


4. `Model Evaluation and Comparison:`

    `Evaluation Metrics:` 
    Utilize metrics such as accuracy, precision, recall, F1-score,to assess each model's performance.

5. `Predictive Performance:`
    Determine which model performs best on the test data based on the chosen evaluation metrics.

6.  `Insights and Conclusion:`
    Draw conclusions from the model comparisons and provide insights into which models are most effective for predicting heart disease in this specific dataset.
    
## Models to be trained

I will be training the following models on the dataset:

1. Decision Tree
2. Random Forest
3. XGBoost

## Evaluation Metrics:

The performance of these models will be assessed using the following metrics, which are crucial for determining their effectiveness in a clinical setting:

1. Accuracy Score
2. Precision Score
3. Recall Score
4. F1 Score

## Final Summary

In this notebook, I have successfully navigated through several critical stages of a data science project using the UCI Heart Disease dataset. My journey included:

`Data Exploration and Preprocessing:`

I have effectively explored and understood the dataset, delving into the specifics of various clinical attributes.
The preprocessing steps, including handling missing values and outliers, were methodically approached, ensuring the data quality for model training.

`Model Training and Evaluation:`

I trained three different models: Decision Tree, Random Forest, and XGBoost, with a focus on predicting the presence of heart disease.
Each model's performance was evaluated using metrics like accuracy, precision, recall, and F1 score.

`Results:`

XGBoost showed slightly superior performance compared to the Decision Tree and Random Forest models, though all models need further tuning for improved accuracy.
